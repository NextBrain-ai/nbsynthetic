# **Tabular synthetic data generator**
Next Brain Synthetic or nbsyntehtic is a simple but robust tabular synthetic data generation library. Synthetic data generation is living a golden age in image generation or speech generation applications. Since the introduction of [Generative Adversarial Networks](https://arxiv.org/pdf/1406.2661.pdf) by Ian J. Goodfellow in 2017, this algorithms have became essential in data generation, overperforming the already existing ones like Variation Autoencoders or Boltzman Machines. GANs are one of the most versatile neural network architectures in use today.
   GANs are made up of two components: generators and discriminators. The generator model produces synthetic samples from random noise collected using a distribution, which are passed to the discriminator, which attempts to differentiate between the two. Both the generator and the discriminator enhance their abilities until the discriminator can no longer tell the difference between actual and synthetic samples. The simultaneous training of generator and discriminator models is inherently unstable. Since its presentation, several variants of GAN have been created in order to increase both, its stabiliuty and its accuracy. For example, with the introduction of additional parameters as an extra condition, discriminator has an additional help the Discriminators in the classsification between real and synthetic data. This variant is knowan as Conditional GAN or CGAN and moves the algorithm from the 'unsuperised learning' field to the 'supervised learning' one, by using this additional 'condition'. Another variant of CGAN are the Auxilary Classifier GAN or ACGAN. The list of improived GAN is long and have been succesfully applied in image generarion applications. 
   
   
##**Why a basic library for synthetic tabular data generation?**

   When it comes to tabular data, the story of GAN have evolved quietly in comparison with image, text and speech generation. There are not many libraries to generate synthetic tabular data and are mostly based in conditional GAN architectures. However, tabular data are by far the most common in the world. Even more, the majority of potential data applications in many industries has to rely in small datasets and, as Data Scinetists use to say, 'poor quality' data. This is the reason why in a data centric approach, the creation of tools for this kind of data is fundamental. We are helping a large hospital in Spain's psychiatric department in a data analysis project. They presented us with a comprehensive research based on data collected over the last ten years. Psychiatric hospitalizations are critical, and this research began with the goal of developing early detection and prevention protocols. We were provided with the results in the form of a spreadsheet with 38 columns and 300 rows. Certainly, that is a small amount of data for any data scientist. It was, however, a challenging effort for them. What are we going to say to them?  Should we tell them that this data is insufficient for using Machine Learning?. Indeed, with this data, the validity of any statistical technique utilized will be put into question. However, this should not be an impediment to maximizing the value from this study by obtaining actionable insights that may be valuable.
   When we have serval dimensions in the original datasets, we have to choose one as an additional 'condition' for our GAN. We will use this dimension or features to condition the generation of the other features. This is certainly practical when we want to use the dataset for a supervised learning problem as a classification or a regression. So we can use our target variable as condition for the GAN.  

##**Unconditional GAN**

fergrtw
